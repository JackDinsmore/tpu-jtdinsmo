{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of the Train time and Inference Time of `MNIST` MLP on CPUs \n",
    "# and GPUs with `keras`\n",
    "\n",
    "### Jack Dinsmore\n",
    "The purpose of this notebook is to determine the relative speeds of training `MNIST` on CPUs and GPUs, as well as the relative speeds of inference. It is a duplication of one of the experiments described in [this paper](https://arxiv.org/pdf/1904.08986.pdf) (arXiv:1904.08986v1 \\[physics.data-an\\]). Next, we will transform the code in this notebook into bare `tensorflow` code and compare runtime, set the GPU implementation up as a service, then transform the code again into a form that can be run on TPUs and perform a similar analysis.\n",
    "\n",
    "The code for the implementations of mnist using MLP with `keras` were pulled from [this github](https://github.com/keras-team/keras/blob/master/examples/mnist_mlp.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Dataset\n",
    "We import all the necessary classes and set some of the globals for the program. `INFERENCE_NUM` is the number of trials we will make when computing the time per inference of the model for each batch size for each machine; we average all the trial times together at the end. `NUM_CLASSES` is the number of categories to train mnist on. `NUM_EPOCHS` describes the number of epochs to run training over. `BATCH_SIZES` is a list of sizes to over which compute runtimes, and it must be sorted from low to high in order for the graph to be made in the last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "from random import random\n",
    "import numpy as np\n",
    "\n",
    "INFERENCE_NUM = 500\n",
    "NUM_CLASSES=10\n",
    "NUM_EPOCHS=5\n",
    "BATCH_SIZES = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we download a dataset using keras and prepare it for training. This need only be done once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test = keras.utils.to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a function to create a `keras` MNIST model. The machine will determine whether the model runs on GPUs or CPUs. The two options are `'/gpu:0'` and `'/cpu:0'`. We will run this function twice, first with CPUs, then with GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(machine):\n",
    "    with tf.device(machine):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=RMSprop(),\n",
    "                      metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data\n",
    "Now we create a function to train a model using a given batch size, then run some inferences and return the time to train the model and the time per inference. We will run this function once per machine type per batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_times(batch_size):\n",
    "    # Compute train time\n",
    "    start_time = time()\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=NUM_EPOCHS,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test))\n",
    "    end_time = time()\n",
    "    train_time = end_time - start_time\n",
    "    \n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "    # Compute inference time\n",
    "    inference_time = 0\n",
    "    for i in range(INFERENCE_NUM): # Do multiple trials\n",
    "        # Create batch_size inputs\n",
    "        inputs = np.random.rand(batch_size, x_train.shape[1])\n",
    "        \n",
    "        #Time inference\n",
    "        start_time = time()\n",
    "        model.predict(inputs)\n",
    "        end_time = time()\n",
    "        inference_time += end_time - start_time\n",
    "    inference_time /= INFERENCE_NUM\n",
    "    \n",
    "    return [train_time, inference_time / batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this function, we get all the data we need for one machine: the train time and the time per inference for every batch size in `BATCH_SIZES`. It will return a list for train times and a list for run times so that the `n`th item of `BATCH_SIZES` will correspond to the `n`th item of `train_times` and `inference_times`. The other two return values are simply to make graphing the data later easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plot():\n",
    "    train_times = []\n",
    "    inference_times = []\n",
    "    max_train = 0\n",
    "    max_inference = 0\n",
    "    for size in BATCH_SIZES:\n",
    "        train_time, inference_time = get_times(size)\n",
    "\n",
    "        train_times.append(train_time)\n",
    "        inference_times.append(inference_time)\n",
    "        max_train = max(max_train, train_time)\n",
    "        max_inference = max(max_inference, inference_time)\n",
    "\n",
    "        print('\\n','Batch size:', size, '\\tTrain time:', train_time, '\\tInference time', inference_time)\n",
    "        print('+'*100)\n",
    "    return train_times, inference_times, max_train, max_inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we execute `get_plot` once for CPUs, and once for GPUs. The following code will generate all the data and will take the most time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN ON CPUS\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 308s 5ms/step - loss: 0.7744 - acc: 0.9169 - val_loss: 0.6855 - val_acc: 0.9440\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 313s 5ms/step - loss: 0.6939 - acc: 0.9446 - val_loss: 0.5800 - val_acc: 0.9550\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 328s 5ms/step - loss: 0.5741 - acc: 0.9546 - val_loss: 0.4128 - val_acc: 0.9682\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 329s 5ms/step - loss: 0.5298 - acc: 0.9592 - val_loss: 0.3985 - val_acc: 0.9687\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 326s 5ms/step - loss: 0.4892 - acc: 0.9617 - val_loss: 0.3868 - val_acc: 0.9711\n",
      "\n",
      " Batch size: 1 \tTrain time: 1605.2057580947876 \tInference time 0.0007146453857421875\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 204s 3ms/step - loss: 0.4232 - acc: 0.9667 - val_loss: 0.3535 - val_acc: 0.9726\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 215s 4ms/step - loss: 0.4001 - acc: 0.9688 - val_loss: 0.3463 - val_acc: 0.9732\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 212s 4ms/step - loss: 0.4185 - acc: 0.9685 - val_loss: 0.3358 - val_acc: 0.9747\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 214s 4ms/step - loss: 0.3769 - acc: 0.9715 - val_loss: 0.3272 - val_acc: 0.9759\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 196s 3ms/step - loss: 0.3648 - acc: 0.9723 - val_loss: 0.3349 - val_acc: 0.9740\n",
      "\n",
      " Batch size: 2 \tTrain time: 1040.9091215133667 \tInference time 0.00043048691749572756\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 137s 2ms/step - loss: 0.3494 - acc: 0.9730 - val_loss: 0.2860 - val_acc: 0.9774\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 142s 2ms/step - loss: 0.3279 - acc: 0.9750 - val_loss: 0.3311 - val_acc: 0.9760\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 141s 2ms/step - loss: 0.3237 - acc: 0.9755 - val_loss: 0.3663 - val_acc: 0.9725\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 153s 3ms/step - loss: 0.3000 - acc: 0.9771 - val_loss: 0.3251 - val_acc: 0.9761\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 147s 2ms/step - loss: 0.3122 - acc: 0.9764 - val_loss: 0.3376 - val_acc: 0.9744\n",
      "\n",
      " Batch size: 3 \tTrain time: 718.9493882656097 \tInference time 0.0003207882245381673\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 105s 2ms/step - loss: 0.2800 - acc: 0.9787 - val_loss: 0.2715 - val_acc: 0.9798\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 110s 2ms/step - loss: 0.2668 - acc: 0.9794 - val_loss: 0.2705 - val_acc: 0.9798\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 104s 2ms/step - loss: 0.2623 - acc: 0.9798 - val_loss: 0.2839 - val_acc: 0.9786\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 103s 2ms/step - loss: 0.2610 - acc: 0.9795 - val_loss: 0.2693 - val_acc: 0.9801\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 103s 2ms/step - loss: 0.2545 - acc: 0.9805 - val_loss: 0.2713 - val_acc: 0.9804\n",
      "\n",
      " Batch size: 4 \tTrain time: 525.344420671463 \tInference time 0.00022665655612945558\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.2384 - acc: 0.9818 - val_loss: 0.2724 - val_acc: 0.9795\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 88s 1ms/step - loss: 0.2259 - acc: 0.9822 - val_loss: 0.2895 - val_acc: 0.9782\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 87s 1ms/step - loss: 0.2327 - acc: 0.9822 - val_loss: 0.3089 - val_acc: 0.9776\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 88s 1ms/step - loss: 0.2117 - acc: 0.9837 - val_loss: 0.2506 - val_acc: 0.9815\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 87s 1ms/step - loss: 0.2064 - acc: 0.9835 - val_loss: 0.2491 - val_acc: 0.9808\n",
      "\n",
      " Batch size: 5 \tTrain time: 434.5743992328644 \tInference time 0.00019843101501464843\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 78s 1ms/step - loss: 0.2173 - acc: 0.9832 - val_loss: 0.2562 - val_acc: 0.9803\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1944 - acc: 0.9846 - val_loss: 0.2467 - val_acc: 0.9808\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1831 - acc: 0.9856 - val_loss: 0.2441 - val_acc: 0.9814\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 76s 1ms/step - loss: 0.1841 - acc: 0.9857 - val_loss: 0.2338 - val_acc: 0.9822\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 71s 1ms/step - loss: 0.1821 - acc: 0.9857 - val_loss: 0.2665 - val_acc: 0.9802\n",
      "\n",
      " Batch size: 6 \tTrain time: 384.15738892555237 \tInference time 0.00018458366394042967\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.1793 - acc: 0.9859 - val_loss: 0.2542 - val_acc: 0.9806\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 60s 1000us/step - loss: 0.1668 - acc: 0.9869 - val_loss: 0.2519 - val_acc: 0.9811\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1794 - acc: 0.9861 - val_loss: 0.2561 - val_acc: 0.9809\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1644 - acc: 0.9869 - val_loss: 0.2290 - val_acc: 0.9828\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1599 - acc: 0.9871 - val_loss: 0.2316 - val_acc: 0.9823\n",
      "\n",
      " Batch size: 7 \tTrain time: 307.65124797821045 \tInference time 0.00016433007376534598\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 56s 936us/step - loss: 0.1464 - acc: 0.9883 - val_loss: 0.2573 - val_acc: 0.9800\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 58s 969us/step - loss: 0.1496 - acc: 0.9879 - val_loss: 0.2426 - val_acc: 0.9815\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 57s 942us/step - loss: 0.1437 - acc: 0.9885 - val_loss: 0.2531 - val_acc: 0.9812\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 55s 917us/step - loss: 0.1450 - acc: 0.9886 - val_loss: 0.2316 - val_acc: 0.9819\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 55s 917us/step - loss: 0.1415 - acc: 0.9886 - val_loss: 0.2429 - val_acc: 0.9813\n",
      "\n",
      " Batch size: 8 \tTrain time: 280.97259736061096 \tInference time 0.0001379685401916504\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 52s 863us/step - loss: 0.1450 - acc: 0.9884 - val_loss: 0.2337 - val_acc: 0.9808\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 56s 933us/step - loss: 0.1363 - acc: 0.9891 - val_loss: 0.2416 - val_acc: 0.9816\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 54s 900us/step - loss: 0.1365 - acc: 0.9893 - val_loss: 0.2383 - val_acc: 0.9817\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 52s 870us/step - loss: 0.1172 - acc: 0.9906 - val_loss: 0.2238 - val_acc: 0.9823\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 53s 888us/step - loss: 0.1193 - acc: 0.9905 - val_loss: 0.2331 - val_acc: 0.9823\n",
      "\n",
      " Batch size: 9 \tTrain time: 267.255779504776 \tInference time 0.00012929084565904404\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 52s 872us/step - loss: 0.1296 - acc: 0.9896 - val_loss: 0.2458 - val_acc: 0.9813\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 52s 862us/step - loss: 0.1173 - acc: 0.9905 - val_loss: 0.2341 - val_acc: 0.9819\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 50s 835us/step - loss: 0.1110 - acc: 0.9909 - val_loss: 0.2247 - val_acc: 0.9822\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 49s 823us/step - loss: 0.1211 - acc: 0.9902 - val_loss: 0.2337 - val_acc: 0.9824\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 47s 780us/step - loss: 0.1199 - acc: 0.9905 - val_loss: 0.2370 - val_acc: 0.9820\n",
      "\n",
      " Batch size: 10 \tTrain time: 250.3245496749878 \tInference time 0.00013227205276489256\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 30s 502us/step - loss: 0.1112 - acc: 0.9911 - val_loss: 0.2392 - val_acc: 0.9829\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 28s 468us/step - loss: 0.1040 - acc: 0.9915 - val_loss: 0.2391 - val_acc: 0.9819\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 27s 454us/step - loss: 0.1081 - acc: 0.9914 - val_loss: 0.2425 - val_acc: 0.9815\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 29s 479us/step - loss: 0.1020 - acc: 0.9919 - val_loss: 0.2367 - val_acc: 0.9816\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 28s 468us/step - loss: 0.1011 - acc: 0.9917 - val_loss: 0.2201 - val_acc: 0.9831\n",
      "\n",
      " Batch size: 20 \tTrain time: 142.32480120658875 \tInference time 7.917339801788331e-05\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 22s 363us/step - loss: 0.0978 - acc: 0.9922 - val_loss: 0.2267 - val_acc: 0.9824\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 22s 365us/step - loss: 0.1001 - acc: 0.9919 - val_loss: 0.2138 - val_acc: 0.9836\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 22s 362us/step - loss: 0.0935 - acc: 0.9924 - val_loss: 0.2145 - val_acc: 0.9830\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 21s 354us/step - loss: 0.0910 - acc: 0.9922 - val_loss: 0.2164 - val_acc: 0.9834\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 21s 347us/step - loss: 0.0785 - acc: 0.9934 - val_loss: 0.2132 - val_acc: 0.9831\n",
      "\n",
      " Batch size: 30 \tTrain time: 107.4438271522522 \tInference time 7.100985844930013e-05\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 18s 296us/step - loss: 0.0803 - acc: 0.9936 - val_loss: 0.2196 - val_acc: 0.9831\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 18s 305us/step - loss: 0.0793 - acc: 0.9935 - val_loss: 0.2233 - val_acc: 0.9828\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 17s 283us/step - loss: 0.0810 - acc: 0.9933 - val_loss: 0.2027 - val_acc: 0.9832\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 17s 279us/step - loss: 0.0788 - acc: 0.9937 - val_loss: 0.2070 - val_acc: 0.9836\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 17s 277us/step - loss: 0.0826 - acc: 0.9934 - val_loss: 0.2044 - val_acc: 0.9835\n",
      "\n",
      " Batch size: 40 \tTrain time: 86.41588592529297 \tInference time 7.678401470184326e-05\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 15s 254us/step - loss: 0.0799 - acc: 0.9936 - val_loss: 0.2137 - val_acc: 0.9831\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 15s 255us/step - loss: 0.0769 - acc: 0.9936 - val_loss: 0.2242 - val_acc: 0.9827\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 15s 258us/step - loss: 0.0747 - acc: 0.9939 - val_loss: 0.2203 - val_acc: 0.9828\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 15s 252us/step - loss: 0.0753 - acc: 0.9940 - val_loss: 0.2035 - val_acc: 0.9844\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 16s 260us/step - loss: 0.0745 - acc: 0.9938 - val_loss: 0.2081 - val_acc: 0.9834\n",
      "\n",
      " Batch size: 50 \tTrain time: 76.76467514038086 \tInference time 7.104716300964356e-05\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 14s 235us/step - loss: 0.0692 - acc: 0.9943 - val_loss: 0.2151 - val_acc: 0.9832\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 14s 230us/step - loss: 0.0723 - acc: 0.9939 - val_loss: 0.1963 - val_acc: 0.9835\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 14s 231us/step - loss: 0.0605 - acc: 0.9949 - val_loss: 0.2029 - val_acc: 0.9832\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 14s 231us/step - loss: 0.0693 - acc: 0.9941 - val_loss: 0.2117 - val_acc: 0.9828\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 14s 226us/step - loss: 0.0703 - acc: 0.9942 - val_loss: 0.2012 - val_acc: 0.9841\n",
      "\n",
      " Batch size: 60 \tTrain time: 69.26433515548706 \tInference time 6.499974727630615e-05\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 0.0639 - acc: 0.9948 - val_loss: 0.2105 - val_acc: 0.9831\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 0.0623 - acc: 0.9948 - val_loss: 0.2178 - val_acc: 0.9826\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 0.0614 - acc: 0.9950 - val_loss: 0.1849 - val_acc: 0.9841\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 0.0628 - acc: 0.9946 - val_loss: 0.2106 - val_acc: 0.9826\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 0.0576 - acc: 0.9953 - val_loss: 0.2187 - val_acc: 0.9823\n",
      "\n",
      " Batch size: 70 \tTrain time: 64.32616329193115 \tInference time 7.251091684613908e-05\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0565 - acc: 0.9953 - val_loss: 0.2082 - val_acc: 0.9837\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0585 - acc: 0.9952 - val_loss: 0.2022 - val_acc: 0.9836\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.0551 - acc: 0.9953 - val_loss: 0.2080 - val_acc: 0.9828\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0583 - acc: 0.9952 - val_loss: 0.2124 - val_acc: 0.9839\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.0548 - acc: 0.9953 - val_loss: 0.2090 - val_acc: 0.9837\n",
      "\n",
      " Batch size: 80 \tTrain time: 59.988348722457886 \tInference time 6.754441261291504e-05\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.0525 - acc: 0.9955 - val_loss: 0.2059 - val_acc: 0.9827\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.0517 - acc: 0.9958 - val_loss: 0.2111 - val_acc: 0.9833\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 11s 192us/step - loss: 0.0523 - acc: 0.9957 - val_loss: 0.1970 - val_acc: 0.9842\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.0572 - acc: 0.9953 - val_loss: 0.2034 - val_acc: 0.9838\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0519 - acc: 0.9956 - val_loss: 0.1920 - val_acc: 0.9842\n",
      "\n",
      " Batch size: 90 \tTrain time: 57.80539417266846 \tInference time 6.521679030524359e-05\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.0531 - acc: 0.9955 - val_loss: 0.2074 - val_acc: 0.9838\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0486 - acc: 0.9959 - val_loss: 0.1909 - val_acc: 0.9844\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 11s 187us/step - loss: 0.0498 - acc: 0.9958 - val_loss: 0.1890 - val_acc: 0.9846\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0497 - acc: 0.9959 - val_loss: 0.1924 - val_acc: 0.9848\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 11s 187us/step - loss: 0.0510 - acc: 0.9954 - val_loss: 0.1947 - val_acc: 0.9846\n",
      "\n",
      " Batch size: 100 \tTrain time: 55.80578017234802 \tInference time 6.802988052368163e-05\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "TRAIN ON GPUS\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 247s 4ms/step - loss: 0.7906 - acc: 0.9153 - val_loss: 0.6565 - val_acc: 0.9452\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 258s 4ms/step - loss: 0.6713 - acc: 0.9452 - val_loss: 0.5354 - val_acc: 0.9559\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 247s 4ms/step - loss: 0.5594 - acc: 0.9555 - val_loss: 0.4780 - val_acc: 0.9637\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 241s 4ms/step - loss: 0.5184 - acc: 0.9590 - val_loss: 0.4276 - val_acc: 0.9673\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 244s 4ms/step - loss: 0.4938 - acc: 0.9617 - val_loss: 0.4119 - val_acc: 0.9685\n",
      "\n",
      " Batch size: 1 \tTrain time: 1237.814959526062 \tInference time 0.0008315749168395996\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 126s 2ms/step - loss: 0.4133 - acc: 0.9677 - val_loss: 0.3623 - val_acc: 0.9721\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 127s 2ms/step - loss: 0.3800 - acc: 0.9700 - val_loss: 0.3732 - val_acc: 0.9721\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 132s 2ms/step - loss: 0.3741 - acc: 0.9706 - val_loss: 0.3186 - val_acc: 0.9753\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 134s 2ms/step - loss: 0.3636 - acc: 0.9719 - val_loss: 0.3637 - val_acc: 0.9718\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 132s 2ms/step - loss: 0.3526 - acc: 0.9724 - val_loss: 0.3361 - val_acc: 0.9744\n",
      "\n",
      " Batch size: 2 \tTrain time: 651.5511710643768 \tInference time 0.0003591029644012451\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 86s 1ms/step - loss: 0.3274 - acc: 0.9741 - val_loss: 0.3221 - val_acc: 0.9758\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.3070 - acc: 0.9755 - val_loss: 0.2947 - val_acc: 0.9766\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.2888 - acc: 0.9774 - val_loss: 0.2918 - val_acc: 0.9770\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 84s 1ms/step - loss: 0.2797 - acc: 0.9783 - val_loss: 0.3093 - val_acc: 0.9756\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 83s 1ms/step - loss: 0.2680 - acc: 0.9789 - val_loss: 0.3149 - val_acc: 0.9762\n",
      "\n",
      " Batch size: 3 \tTrain time: 423.1729016304016 \tInference time 0.000237180233001709\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.2608 - acc: 0.9796 - val_loss: 0.2664 - val_acc: 0.9799\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.2468 - acc: 0.9805 - val_loss: 0.2853 - val_acc: 0.9775\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.2492 - acc: 0.9806 - val_loss: 0.2841 - val_acc: 0.9778\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.2411 - acc: 0.9813 - val_loss: 0.2459 - val_acc: 0.9803\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.2400 - acc: 0.9818 - val_loss: 0.2755 - val_acc: 0.9795\n",
      "\n",
      " Batch size: 4 \tTrain time: 311.92014741897583 \tInference time 0.0001805802583694458\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 50s 827us/step - loss: 0.2237 - acc: 0.9822 - val_loss: 0.2816 - val_acc: 0.9788\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 51s 847us/step - loss: 0.2107 - acc: 0.9832 - val_loss: 0.2521 - val_acc: 0.9803\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 51s 848us/step - loss: 0.2127 - acc: 0.9833 - val_loss: 0.2603 - val_acc: 0.9790\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 51s 843us/step - loss: 0.1945 - acc: 0.9845 - val_loss: 0.2464 - val_acc: 0.9807\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 51s 849us/step - loss: 0.2007 - acc: 0.9842 - val_loss: 0.2740 - val_acc: 0.9794\n",
      "\n",
      " Batch size: 5 \tTrain time: 252.85755395889282 \tInference time 0.00014632673263549804\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 42s 702us/step - loss: 0.1893 - acc: 0.9855 - val_loss: 0.2419 - val_acc: 0.9819\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 42s 704us/step - loss: 0.1819 - acc: 0.9855 - val_loss: 0.2693 - val_acc: 0.9789\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 42s 703us/step - loss: 0.1826 - acc: 0.9855 - val_loss: 0.2441 - val_acc: 0.9809\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 42s 699us/step - loss: 0.1791 - acc: 0.9859 - val_loss: 0.2368 - val_acc: 0.9813\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 42s 699us/step - loss: 0.1734 - acc: 0.9861 - val_loss: 0.2302 - val_acc: 0.9813\n",
      "\n",
      " Batch size: 6 \tTrain time: 210.41955661773682 \tInference time 0.00012122654914855957\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 36s 602us/step - loss: 0.1727 - acc: 0.9864 - val_loss: 0.2494 - val_acc: 0.9805\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 36s 596us/step - loss: 0.1627 - acc: 0.9871 - val_loss: 0.2388 - val_acc: 0.9814\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 36s 598us/step - loss: 0.1491 - acc: 0.9884 - val_loss: 0.2285 - val_acc: 0.9824\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 36s 599us/step - loss: 0.1460 - acc: 0.9882 - val_loss: 0.2318 - val_acc: 0.9821\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 36s 594us/step - loss: 0.1429 - acc: 0.9886 - val_loss: 0.2216 - val_acc: 0.9827\n",
      "\n",
      " Batch size: 7 \tTrain time: 179.42340993881226 \tInference time 0.00010433340072631837\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 31s 521us/step - loss: 0.1453 - acc: 0.9884 - val_loss: 0.2392 - val_acc: 0.9818\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 31s 516us/step - loss: 0.1381 - acc: 0.9890 - val_loss: 0.2309 - val_acc: 0.9829\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 32s 536us/step - loss: 0.1369 - acc: 0.9892 - val_loss: 0.2287 - val_acc: 0.9827\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 31s 517us/step - loss: 0.1381 - acc: 0.9888 - val_loss: 0.2170 - val_acc: 0.9835\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 31s 516us/step - loss: 0.1267 - acc: 0.9896 - val_loss: 0.2301 - val_acc: 0.9824\n",
      "\n",
      " Batch size: 8 \tTrain time: 156.38233137130737 \tInference time 9.006369113922119e-05\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 28s 472us/step - loss: 0.1387 - acc: 0.9890 - val_loss: 0.2354 - val_acc: 0.9822\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 28s 463us/step - loss: 0.1235 - acc: 0.9900 - val_loss: 0.2295 - val_acc: 0.9820\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 28s 459us/step - loss: 0.1206 - acc: 0.9901 - val_loss: 0.2170 - val_acc: 0.9836\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 29s 482us/step - loss: 0.1200 - acc: 0.9903 - val_loss: 0.2257 - val_acc: 0.9822\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 28s 471us/step - loss: 0.1184 - acc: 0.9905 - val_loss: 0.2096 - val_acc: 0.9836\n",
      "\n",
      " Batch size: 9 \tTrain time: 140.8433268070221 \tInference time 8.198648028903537e-05\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 26s 427us/step - loss: 0.1150 - acc: 0.9906 - val_loss: 0.2207 - val_acc: 0.9823\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 25s 424us/step - loss: 0.1157 - acc: 0.9903 - val_loss: 0.2248 - val_acc: 0.9822\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 25s 419us/step - loss: 0.1115 - acc: 0.9906 - val_loss: 0.2231 - val_acc: 0.9823\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 25s 424us/step - loss: 0.1067 - acc: 0.9913 - val_loss: 0.2170 - val_acc: 0.9835\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 25s 420us/step - loss: 0.1043 - acc: 0.9915 - val_loss: 0.2280 - val_acc: 0.9821\n",
      "\n",
      " Batch size: 10 \tTrain time: 126.83609676361084 \tInference time 7.610840797424316e-05\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 0.1051 - acc: 0.9913 - val_loss: 0.2470 - val_acc: 0.9818\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 0.0988 - acc: 0.9921 - val_loss: 0.2173 - val_acc: 0.9833\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 0.0989 - acc: 0.9917 - val_loss: 0.2169 - val_acc: 0.9833\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 13s 215us/step - loss: 0.0956 - acc: 0.9922 - val_loss: 0.2132 - val_acc: 0.9842\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 13s 211us/step - loss: 0.0999 - acc: 0.9920 - val_loss: 0.2154 - val_acc: 0.9837\n",
      "\n",
      " Batch size: 20 \tTrain time: 65.22027158737183 \tInference time 3.8336467742919924e-05\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.0930 - acc: 0.9925 - val_loss: 0.2078 - val_acc: 0.9838\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0876 - acc: 0.9927 - val_loss: 0.2098 - val_acc: 0.9836\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.0853 - acc: 0.9927 - val_loss: 0.2036 - val_acc: 0.9841\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.0833 - acc: 0.9933 - val_loss: 0.2049 - val_acc: 0.9848\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0808 - acc: 0.9931 - val_loss: 0.2303 - val_acc: 0.9827\n",
      "\n",
      " Batch size: 30 \tTrain time: 42.72523522377014 \tInference time 2.6758972803751626e-05\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0781 - acc: 0.9938 - val_loss: 0.2089 - val_acc: 0.9836\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.0820 - acc: 0.9932 - val_loss: 0.1930 - val_acc: 0.9852\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0840 - acc: 0.9931 - val_loss: 0.2121 - val_acc: 0.9839\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0770 - acc: 0.9937 - val_loss: 0.2042 - val_acc: 0.9842\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0749 - acc: 0.9940 - val_loss: 0.2016 - val_acc: 0.9841\n",
      "\n",
      " Batch size: 40 \tTrain time: 32.81451892852783 \tInference time 3.7921130657196046e-05\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0726 - acc: 0.9942 - val_loss: 0.1914 - val_acc: 0.9849\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0787 - acc: 0.9934 - val_loss: 0.2052 - val_acc: 0.9844\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0720 - acc: 0.9940 - val_loss: 0.1936 - val_acc: 0.9848\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0707 - acc: 0.9941 - val_loss: 0.1994 - val_acc: 0.9843\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0723 - acc: 0.9942 - val_loss: 0.1942 - val_acc: 0.9849\n",
      "\n",
      " Batch size: 50 \tTrain time: 26.9878351688385 \tInference time 3.139569282531739e-05\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.0711 - acc: 0.9941 - val_loss: 0.2016 - val_acc: 0.9842\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 0.0655 - acc: 0.9947 - val_loss: 0.2033 - val_acc: 0.9848\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.0648 - acc: 0.9947 - val_loss: 0.2025 - val_acc: 0.9848\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.0624 - acc: 0.9947 - val_loss: 0.2141 - val_acc: 0.9835\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.0625 - acc: 0.9946 - val_loss: 0.2084 - val_acc: 0.9838\n",
      "\n",
      " Batch size: 60 \tTrain time: 22.918389081954956 \tInference time 2.575569152832031e-05\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.0606 - acc: 0.9947 - val_loss: 0.1978 - val_acc: 0.9842\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0577 - acc: 0.9950 - val_loss: 0.2023 - val_acc: 0.9841\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0583 - acc: 0.9949 - val_loss: 0.2065 - val_acc: 0.9833\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0603 - acc: 0.9949 - val_loss: 0.2048 - val_acc: 0.9839\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.0603 - acc: 0.9949 - val_loss: 0.2008 - val_acc: 0.9846\n",
      "\n",
      " Batch size: 70 \tTrain time: 19.86325216293335 \tInference time 3.233137811933245e-05\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0538 - acc: 0.9955 - val_loss: 0.2005 - val_acc: 0.9845\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0572 - acc: 0.9954 - val_loss: 0.1955 - val_acc: 0.9848\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0568 - acc: 0.9953 - val_loss: 0.2070 - val_acc: 0.9837\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0510 - acc: 0.9960 - val_loss: 0.1954 - val_acc: 0.9847\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0545 - acc: 0.9955 - val_loss: 0.2094 - val_acc: 0.9832\n",
      "\n",
      " Batch size: 80 \tTrain time: 17.325928926467896 \tInference time 2.8447258472442628e-05\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.0552 - acc: 0.9953 - val_loss: 0.2126 - val_acc: 0.9837\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.0528 - acc: 0.9956 - val_loss: 0.2132 - val_acc: 0.9837\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.0515 - acc: 0.9956 - val_loss: 0.2108 - val_acc: 0.9835\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.0528 - acc: 0.9957 - val_loss: 0.2062 - val_acc: 0.9840\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0486 - acc: 0.9958 - val_loss: 0.1992 - val_acc: 0.9839\n",
      "\n",
      " Batch size: 90 \tTrain time: 16.198907613754272 \tInference time 2.6076147291395398e-05\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.0517 - acc: 0.9955 - val_loss: 0.1952 - val_acc: 0.9839\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0475 - acc: 0.9960 - val_loss: 0.2007 - val_acc: 0.9844\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0487 - acc: 0.9959 - val_loss: 0.1991 - val_acc: 0.9847\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.0523 - acc: 0.9955 - val_loss: 0.1934 - val_acc: 0.9851\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.0510 - acc: 0.9956 - val_loss: 0.1887 - val_acc: 0.9845\n",
      "\n",
      " Batch size: 100 \tTrain time: 14.52865719795227 \tInference time 3.0204300880432132e-05\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAIN ON CPUS\")\n",
    "print()\n",
    "model = create_model('/cpu:0')\n",
    "cpu_train_times, cpu_inference_times, max_train, max_inference = get_plot()\n",
    "\n",
    "print()\n",
    "print(\"TRAIN ON GPUS\")\n",
    "print()\n",
    "print('+'*100)\n",
    "model = create_model('/gpu:0')\n",
    "gpu_train_times, gpu_inference_times, gpu_max_train, gpu_max_inference = get_plot()\n",
    "\n",
    "print()\n",
    "print(\"DONE\")\n",
    "\n",
    "max_train = max(max_train, gpu_max_train)\n",
    "max_inference = max(max_inference, gpu_max_inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Data\n",
    "Now we wish to compare train time and inference time between CPUs and GPUs. We will make two plots, one for train time and one for inference time. First, we import the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we trainsfer the data we've collected into `numpy` arrays for use in `matplotlib`, and change the units on the inference graph vertical axis to be more appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNITS = 's ms us ns'.split()\n",
    "unit_index = 0\n",
    "\n",
    "while max_inference < 1:\n",
    "    for i in range(len(cpu_inference_times)):\n",
    "        cpu_inference_times[i] *= 1000\n",
    "        gpu_inference_times[i] *= 1000\n",
    "    max_inference *= 1000\n",
    "    unit_index += 1\n",
    "if unit_index >= len(UNITS):\n",
    "    raise RuntimeError('Your inference times ('+str(max_inference / 1000**unit_index)+') are unreasonably small.')\n",
    "    \n",
    "x = np.array(BATCH_SIZES)\n",
    "cpu_train_times = np.array(cpu_train_times)\n",
    "cpu_inference_times = np.array(cpu_inference_times)\n",
    "gpu_train_times = np.array(gpu_train_times)\n",
    "gpu_inference_times = np.array(gpu_inference_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the train time as a function of batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, cpu_train_times, c='r', alpha = 0.5)\n",
    "plt.scatter(x, gpu_train_times, c='b', alpha = 0.5, marker='s')\n",
    "plt.xlabel('Batch size')\n",
    "plt.ylabel('Train time (s)')\n",
    "plt.legend(['CPU', 'GPU'])\n",
    "plt.axis([0, BATCH_SIZES[-1]*1.1, 0, max_train*1.1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the time per inference as a function of batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, cpu_inference_times, c='r', alpha = 0.5)\n",
    "plt.scatter(x, gpu_inference_times, c='b', alpha = 0.5, marker='s')\n",
    "plt.xlabel('Batch size')\n",
    "plt.ylabel('Time per inference ('+UNITS[unit_index]+')')\n",
    "plt.legend(['CPU', 'GPU'])\n",
    "plt.axis([0, BATCH_SIZES[-1]*1.1, 0, max_inference*1.1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also make a couple other plots, such as the performance gain in using gpus over cpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gain_train = []\n",
    "for i in range(cpu_train_times.shape[0]):\n",
    "    gain_train.append(cpu_train_times[i] / gpu_train_times[i] * 100)\n",
    "gain_train = np.array(gain_train)\n",
    "\n",
    "gain_inference = []\n",
    "for i in range(cpu_inference_times.shape[0]):\n",
    "    gain_inference.append(cpu_inference_times[i] / gpu_inference_times[i] * 100)\n",
    "gain_inference = np.array(gain_inference)\n",
    "\n",
    "plt.scatter(x, gain_train, c='g', alpha = 0.5, marker = '^')\n",
    "plt.xlabel('Batch size')\n",
    "plt.ylabel('Speed gain by using GPUs instead of CPUs (%)')\n",
    "plt.legend(['Train time', 'Inference time'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, gain_inference, c='m', alpha = 0.5, marker='v')\n",
    "plt.xlabel('Batch size')\n",
    "plt.ylabel('Speed gain by using GPUs instead of CPUs (%)')\n",
    "plt.legend(['Train time', 'Inference time'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collection of the above data concludes this experiment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
